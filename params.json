{"name":"Loggex","tagline":"An example project using Ecto and Plug.Router","body":"I've been working with a couple of Elixir technologies lately, Plug.Router and Ecto, and I'm pretty pleased with how easy it is to get them working together. Here's an example -- let's say I want to write a logger. The logger takes in whatever message hits it's log endpoint and writes it to a database. We'll write a proof of concept logger in this post, [you can find the code on GitHub](https://github.com/philosodad/loggex). Occasionally you'll see a cryptic note like this [[s0]](https://github.com/philosodad/loggex), that is an indication that the code up to that point is available under the indicated tag. \r\n\r\nIf you want to follow along with this exercise, you're going to need to have elixir and postgresql installed on your computer, or if you are a user of vagrant, you can try a prebuilt box for phoenix development like [this one](https://github.com/kiere/vagrant-phoenix-postgres). I haven't tried that box, but it's worth a shot.\r\n\r\nWe're going to use the logger to record the time the original message was received, the response code for the message, and the body of the message. So my endpoint is going to expect a block of JSON that looks something like this:\r\n\r\n    { \r\n      sender: \"something.com\" \r\n      time: <datetime>, \r\n      responseCode: 300, \r\n      body: \"\\{\\\"foo\\\": \\\"bar\\\"\\}\"\r\n    }\r\n\r\nAnd we're going to put that into a postgres database in a table that's called \"messages\".\r\n\r\nSo, we'll need to start a new elixir project:\r\n\r\n    $ mix new loggex\r\n    $ cd loggex\r\n\r\nAnd add some dependencies to the `mix.exs` file. We'll need to add cowboy, plug, ecto, and postgrex:\r\n\r\n    def application do\r\n      [applications: \r\n        [:logger,\r\n         :cowboy,\r\n         :plug,\r\n         :postgrex,\r\n         :ecto]\r\n      ]\r\n    end \r\n    defp deps do\r\n      [\r\n        {:httpoison, \"~> 0.8.0\"},\r\n        {:cowboy, \"~> 1.0.0\"},\r\n        {:plug, \"~> 1.0\"},\r\n        {:exjsx, \"~> 3.2\"},\r\n        {:postgrex, \">= 0.0.0\"},\r\n        {:ecto, \"~> 1.1.2\"}\r\n      ]\r\n    end\r\n\r\n[[s1]](https://github.com/philosodad/loggex/tree/s1)[Plug](https://github.com/elixir-lang/plug) is the middleware framework that contains Plug.Router, [Cowboy](https://github.com/ninenines/cowboy) is a web server from Erlang, [Ecto](https://github.com/elixir-lang/ecto) is the database wrapper and [Postgrex](https://github.com/ericmj/postgrex) is the adapter between Ecto and Postgres. We could use a different database, there are several adapters available, but Postgres is sort of the defacto standard so we'll stick with it. Of course, once you have those dependencies noted you'll want to run `mix deps.get` to install them all.\r\n\r\nNow that we're set up, we'll first add a route, then add the database migration, then wire it together to save the incoming message to the database. A quick side note, I'll be driving this with tests on my side but not including them in the post. The tests are in the GitHub repo, though.\r\n\r\nAdding a route looks pretty simple, if you're familiar with Sinatra this probably looks familiar to you:\r\n\r\n    defmodule Loggex do\r\n      use Plug.Router\r\n      plug :match\r\n      plug :dispatch\r\n\r\n      post \"/log\" do\r\n        send_resp(conn, 200, \"No Response\")\r\n      end\r\n    end\r\n\r\nTo start the router, use `iex -S mix` to start an iex session, and in iex:\r\n\r\n    > Plug.Adapters.Cowboy.http Loggex, [], port: 6438\r\n\r\nThe port option is optional, it defaults to 4000. I have about six servers running on my laptop right now, so I'm getting creative with port numbers. In a later post we might look at how to make these values configurable, as well as how to start the server from the command line rather than from iex.\r\n\r\nAt this point, if you send an http request to `localhost:6438/log`, you should receive a 200 response back[[s2]](https://github.com/philosodad/loggex/tree/s2).\r\n\r\nNext, we want to set up the database with ecto. Ecto has it's own mix tasks, which makes this somewhat easier.\r\n\r\n    $ mix ecto.gen.repo\r\n\r\nThis will generate a new file in `lib/loggex/` called `repo.ex`. You don't have to do anything to the repo file, but there are also changes to be made to your `config.exs` file. That file will now have some new material in it:\r\n\r\n    use Mix.Config\r\n    config :loggex, Loggex.Repo,\r\n      adapter: Ecto.Adapters.Postgres,\r\n      database: \"loggex_repo\",\r\n      username: \"user\", #CHANGE THIS LINE\r\n      password: \"pass\", #CHANGE THIS LINE\r\n      hostname: \"localhost\"\r\n\r\nThe `username` and `password` entries will need to be changed to a user on your installation of postgres. Once we have a repository, we can create the repository and generate a migration.\r\n\r\n    :::bash\r\n    $ mix ecto.create\r\n    $ mix ecto.gen.migration add_loglines_table\r\n\r\nThis produces a basic migration file in `priv/repo/migrations/` which we'll edit to match the JSON schema we started with:\r\n\r\n    defmodule Loggex.Repo.Migrations.AddLoglinesTable do\r\n      use Ecto.Migration\r\n      def change do\r\n        create table(:loglines) do\r\n          add :sender, :string\r\n          add :sendtime, :datetime\r\n          add :responseCode, :integer\r\n          add :body, :string\r\n        end\r\n      end\r\n    end            \r\n\r\nThe `change` function is automatically reversible. Now, in order to be able to work effeciently with our new database and table, we'll want to add a schema at `lib/loggex/logline.ex`.\r\n\r\n    defmodule Loggex.Logline do\r\n      use Ecto.Schema\r\n      import Ecto.Changeset\r\n                                                                                                                                                                                      \r\n      schema \"loglines\" do\r\n        field :sender, :string\r\n        field :sendtime, Ecto.DateTime\r\n        field :responseCode, :integer\r\n        field :body, :string\r\n      end\r\n    end                \r\n\r\nAt this point, using iex, you should be able to start the repo with `Loggex.Repo.start_link` and insert a changeset into the repo. I put a lot of trial and error in, so here's an example iex session. Some of the longer lines have been moved to multiple lines, so you'll want to fix the query, it may not run if just pasted in.\r\n\r\n    ex(1)> {:ok, repo} = Loggex.Repo.start_link\r\n    {:ok, #PID<0.214.0>}\r\n    iex(2)> change = %Loggex.Logline{sender: \"sender\",\r\n                          sendtime: Ecto.DateTime.utc,\r\n                          responseCode: 344,\r\n                          body: \"body goes here\"}\r\n    %Loggex.Logline{__meta__: #Ecto.Schema.Metadata<:built>\r\n    iex(3)> import Ecto.Query\r\n    nil\r\n    iex(4)> Loggex.Repo.insert change\r\n\r\n    16:16:38.577 [debug] INSERT INTO \"loglines\" (\"body\", \"re\r\n    {:ok,\r\n     %Loggex.Logline{__meta__: #Ecto.Schema.Metadata<:loaded\r\n      body: \"body goes here\", id: 3, responseCode: 344, send\r\n      sendtime: #Ecto.DateTime<2016-02-21T21:15:54Z>}}\r\n    iex(5)> query = from l in Loggex.Logline, \r\n                     where: l.responseCode == 344, \r\n                     select: l\r\n    #Ecto.Query<from l in Loggex.Logline, where: l.responseC\r\n    iex(6)> Loggex.Repo.one query\r\n\r\n    16:17:45.614 [debug] SELECT l0.\"id\", l0.\"sender\", l0.\"se\r\n    %Loggex.Logline{__meta__: #Ecto.Schema.Metadata<:loaded>\r\n     body: \"body goes here\", id: 3, responseCode: 344, sende\r\n     sendtime: #Ecto.DateTime<2016-02-21T21:15:54Z>}\r\n    iex(7)> log = Loggex.Repo.one query\r\n\r\n    16:18:00.319 [debug] SELECT l0.\"id\", l0.\"sender\", l0.\"se\r\n    %Loggex.Logline{__meta__: #Ecto.Schema.Metadata<:loaded>\r\n     body: \"body goes here\", id: 3, responseCode: 344, sende\r\n     sendtime: #Ecto.DateTime<2016-02-21T21:15:54Z>}\r\n    iex(8)> log.responseCode\r\n    344\r\n\r\nAll the parts are here at this point[[s3]](https://github.com/philosodad/loggex/tree/s3), we just need to make them work together. Now, I'm fairly sure that there are better ways to do this than the way I've settled on. In particular, I'm doing some pretty gunky stuff to convert the input into a `%Loggex.Logline struct`. But here goes.\r\n\r\nMy first problem is that I've got a requirement to send in an Ecto.DateTime object, but I'll probably be receiving an iso datetime string. We'll take advantage of plug to handle this (again, this is just an example, this probably should go in the Schema).\r\n\r\n    defmodule Loggex do\r\n      use Plug.Router\r\n      use Plug.Builder\r\n\r\n      plug Plug.Parsers, parsers: [:json, :urlencoded],\r\n                         json_decoder: JSX\r\n      plug :timefixer\r\n      plug :match\r\n      plug :dispatch\r\n\r\n      def start do\r\n        Plug.Adapters.Cowboy.http Loggex, [], port: 6438\r\n        Loggex.Repo.start_link\r\n      end\r\n\r\n      def stop do\r\n        Plug.Adapters.Cowboy.shutdown Loggex.HTTP\r\n      end\r\n\r\n      post \"/log\" do\r\n        Map.keys(conn.params)\r\n        |> Enum.reduce(%{}, fn(k,acc) -> \r\n           Map.put(acc, String.to_atom(k), conn.params[k]) \r\n           end)\r\n        |> (&(Map.merge(%Loggex.Logline{}, &1))).()\r\n        |> Loggex.Repo.insert\r\n        send_resp(conn, 200, \"No Response\")\r\n      end\r\n\r\n      def timefixer conn, opts do\r\n        conn = conn.params[\"sendtime\"]\r\n        |> Ecto.DateTime.cast!\r\n        |> (&(Map.put(conn.params, \"sendtime\", &1))).()\r\n        |> (&(Map.put(conn, :params, &1))).()\r\n        conn\r\n      end\r\n\r\n    end\r\n\r\nLet's walk through the plug pipeline one step at a time. The first plug is the JSON parser. It takes in a conn struct, reads the input body, and returns a new conn with a `params` key, the value of which is a map built from the input JSON.\r\n\r\nWe added `Plug.Builder` and a new plug, `:timefixer`, which we define as a function in the module. Time fixer takes the conn struct that the JSON parser returns and typecasts the `\"sendtime\"` value of the `conn.params` into an `Ecto.DateTime` struct, which is what the schema expects. The new conn is passed on to the `:match` plug.\r\n\r\nThe `:match` plug matches the incoming request to the `post \"/log\"` function, where we convert the params that came in into a `%Loggex.Logline{}` struct, so that we can insert that into the database. Again, we make pretty heavy use of the pipeline operator here. After inserting the new logline into the database, we return three values, the conn, a response code, and a message. These are passed to the `:dispatch` plug, which returns a 200 to the user. \r\n\r\nAt this point we have a functional logger[[s4]](https://github.com/philosodad/loggex/tree/s4). It isn't as pretty as it could be, and it definitely needs a little cleanup and some error handling, but provided it gets exactly the right inputs, it will save a logline into the postgres database.\r\n\r\nNext entry I'll look at how to improve this project by adding configuration, CI, and test coverage metrics. And of course you can find the code on GitHub, [https://github.com/philosodad/loggex](https://github.com/philosodad/loggex).","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}